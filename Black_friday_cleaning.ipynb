{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos librerías\n",
    "import sys\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargamos los datos\n",
    "black_data = pd.read_csv(\"BlackFriday.csv\")\n",
    "black_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizamos las variables numéricas de los datos\n",
    "black_data.describe()\n",
    "#verificamos los tipos de valor en cada celda\n",
    "black_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_values = [\"Gender\", \"Age\", \"Occupation\", \"City_Category\", \"Marital_Status\", \"Product_Category_1\", \n",
    "              \"Product_Category_2\", \"Product_Category_3\"]\n",
    "for column in cat_values:\n",
    "    black_data[column] = black_data[column].astype('category')\n",
    "black_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suma de valores pérdidos en cada columna. Pandas reconoce tanto una celda vacía como el valor NA como NaN\n",
    "#https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b\n",
    "black_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificamos si hay valores pérdidos con otras sintaxis\n",
    "#lista con valores NA comunes\n",
    "missing_values = [\"n/a\", \"na\", \"--\", \"Na\"]\n",
    "black_data = pd.read_csv(\"BlackFriday.csv\", na_values= missing_values)\n",
    "black_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificamos la correlación entre variables para verificar si las variables con valores pérdidos tienen alguna \n",
    "#correlación alta con otra variables\n",
    "black_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificamos el nro de filas que tienen valores pérdidos en las 2 variables\n",
    "len(black_data[black_data['Product_Category_2'].isnull() & black_data['Product_Category_2'].isnull()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificamos la distribución de Product_Category_1 para comparar con los valores pérdidos de Product_Category_2 y\n",
    "#Product_Category_3\n",
    "prod_1 = black_data['Product_ID'].groupby(black_data['Product_Category_1']).nunique()\n",
    "prod_2 = black_data['Product_ID'].groupby(black_data['Product_Category_2']).nunique()\n",
    "prod_3 = black_data['Product_ID'].groupby(black_data['Product_Category_2']).nunique()\n",
    "prod_1\n",
    "\n",
    "bins = np.sort(black_data['Product_Category_1'].unique())\n",
    "plt.xticks(bins)\n",
    "plt.title('Product_Category_1')\n",
    "plt.bar(bins, prod_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_2\n",
    "prod_3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observamos que no hay categoría 0. Por tanto, asignaremos los valores pérdidos el valor 0 para identificar que no se conoce la categoría dentro del tipo de producto 2 y 3 al que pertenecen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sustituimos los valores pérdidos de Product_category_2 y Product_Categori_3 por 0\n",
    "bf_data = black_data.fillna(0)\n",
    "bf_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Representamos el gráfico de cajas de la variable \"Purchase\" y vemos que existen valores extremos \n",
    "plt.figure(figsize=[30,10])\n",
    "plt.subplot(231)\n",
    "cajas = plt.boxplot(x=bf_data['Purchase'], showmeans = True, meanline = True)\n",
    "plt.title('Purchase Boxplot')\n",
    "plt.ylabel('Purchase ($)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos los valores extremos en una lista\n",
    "outliers = list(cajas[\"fliers\"][0].get_data()[1])\n",
    "\n",
    "# Comprobamos la longitud para ver cuántos registros se consideran extremos.\n",
    "print \"Num. extremos\", len(outliers)\n",
    "print \"Num. total\", len(bf_data)\n",
    "\n",
    "# Borramos los datos extremos\n",
    "bf_data = bf_data[~bf_data.Purchase.isin(outliers)]\n",
    "\n",
    "# Comparamos las longitudes antes y después\n",
    "print \"Num. sin extremos\", len(bf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (solo informativo)\n",
    "\n",
    "# Número de valores diferentes por campo\n",
    "print('Número de valores distintos: \\n')\n",
    "for i in bf_data.columns:\n",
    "    print i, ':',bf_data[i].nunique()\n",
    "    \n",
    "# Tipo de datos de cada campo\n",
    "print('\\nTipo de datos: \\n')\n",
    "print (bf_data.info())\n",
    "\n",
    "# Matriz de covarianzas \n",
    "print('\\nMatriz de covarianzas: \\n')\n",
    "bf_data.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cat_values:\n",
    "    bf_data[column] = bf_data[column].astype('category')\n",
    "bf_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#análisis estadístico descriptivo\n",
    "bf_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la única variable continua es Purchase. Al utilizar el comando describe observamos también User_ID, pero en este caso al ser la identificación del usuario no tiene sentido los resultados que se indican de las medidas estadísticas de tendencia central y de dispersión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación de la normalidad y homogeneidad de la varianza "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Como la mayoría de las variables son categóricas, analizaremos la comprobación de normalidad sobre el subset de Purchase que corresponde a las variables categóricas que consideramos relevantes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizamos la distribución de la variable Purchase\n",
    "plt.hist(bf_data['Purchase'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El histograma de la variable Purchase prevee que esta variable no sea normal, aplicamos el test shapiro para esta variable y otros subsets de diferentes categorías  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos el test shapiro sobre una muestra porque en la primera prueba obtenemos una advertencia de que el resultado \n",
    "#de p-value no es preciso para muestras mayores a 5000\n",
    "stats.shapiro(bf_data['Purchase'].sample(n=5000, random_state=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Podemos concluir que la variable Purchase no es normal porque el p-value <0.05. Por tanto, se rechaza la hipótesis nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizamos la normalidad de la variable Purchase sobre las muestras de hombres y mujeres\n",
    "purch_female = stats.shapiro(bf_data['Purchase'][bf_data['Gender']=='F'].sample(n=4000, random_state =1))\n",
    "purch_male = stats.shapiro(bf_data['Purchase'][bf_data['Gender']=='M'].sample(n=4000, random_state =1))\n",
    "if purch_female[1]<0.05:\n",
    "    print (\"la variable no es normal\")\n",
    "else:\n",
    "    print (\"la variable es normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizamos la normalidad de la variable Purchase sobre las muestras de las variables Gender, Age, \n",
    "#City_category y Marital_Status\n",
    "\n",
    "bf_data['Marital_Status'] = bf_data['Marital_Status'].astype('string')\n",
    "data_select = ['Gender', 'Age', 'City_Category', 'Marital_Status']\n",
    "for value in data_select:\n",
    "    var = bf_data[value].unique()\n",
    "    for i in range(len(var)):\n",
    "        shap_num = stats.shapiro(bf_data['Purchase'][bf_data[value]==var[i]].sample(n=4000, random_state =1))\n",
    "        shap_dict = {value +  var[i]: shap_num[1]}\n",
    "        print shap_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observamos que la variable Purchase con respecto a las variables 'Gender', 'Age', 'City_Category', 'Marital_Status' presenta una distribución no normal. Sin embargo, como la muestra es grande podemos aplicar el teorema del límite central para asumir normalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos la homosteceidad \n",
    "for value in data_select:\n",
    "    var = bf_data[value].unique()\n",
    "    for i in range(len(var)):\n",
    "        flig_num = stats.fligner(bf_data['Purchase'], bf_data['Purchase'][bf_data[value]==var[i]])\n",
    "        if flig_num[1] <0.05:\n",
    "            flig_stat = u\"presentan varianzas diferentes\"\n",
    "        elif flig_num[1] >= 0.05:\n",
    "            flig_stat = u\"presentan varianzas similares\"\n",
    "        flig_dict = {value +  var[i] + \" & Purchase\": flig_stat.encode('utf8')}\n",
    "        print flig_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observamos que Purchase presenta varianzas similares con respecto a los siguientes grupos:\n",
    "Personas entre 26 y 45 años\n",
    "Personas entre 51 y 55 años\n",
    "Personas con estado civil representado por '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estudio de la dependencia de variables categóricas: Test Chi Cuadrado \n",
    "user_att = ['Gender', 'Age', 'City_Category', 'Marital_Status', 'Occupation', 'City_Category' ]\n",
    "p_cat = ['Product_Category_1', 'Product_Category_2', 'Product_Category_3']\n",
    "\n",
    "# Nuestra hipótesis nula será que no existe relación entre la categoría de producto\n",
    "# y cada una de las variables en data_select.\n",
    "for i in user_att:\n",
    "    for j in p_cat:\n",
    "        tabla_cont = pd.crosstab(bf_data[i], bf_data[j])\n",
    "        chi2, p, dof, ex = stats.chi2_contingency(tabla_cont, correction=True, lambda_=None)\n",
    "        if p <0.05:\n",
    "            print i, ' es independiente de ', j\n",
    "        else:\n",
    "            print i, ' puede que sea independiente de Product_Category_1, estudiar más a fondo ', j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removemos las variables relacionadas con Product category\n",
    "bf_select = bf_data.drop(['Product_Category_2', 'Product_Category_3'], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bf_select.drop(['Purchase'], axis=1).sample(n=50000, random_state =1)\n",
    "Y = bf_select['Purchase'].sample(n=50000, random_state =1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357216</th>\n",
       "      <td>1001068</td>\n",
       "      <td>P00302742</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389881</th>\n",
       "      <td>1006001</td>\n",
       "      <td>P00354642</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34323</th>\n",
       "      <td>1005302</td>\n",
       "      <td>P00230842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46172</th>\n",
       "      <td>1001121</td>\n",
       "      <td>P00347242</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379025</th>\n",
       "      <td>1004309</td>\n",
       "      <td>P00042842</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID Product_ID  Gender  Age Occupation  City_Category  \\\n",
       "357216  1001068  P00302742       0    1          4              1   \n",
       "389881  1006001  P00354642       0    2          7              0   \n",
       "34323   1005302  P00230842       0    0         10              0   \n",
       "46172   1001121  P00347242       1    6          7              2   \n",
       "379025  1004309  P00042842       1    2          0              2   \n",
       "\n",
       "        Stay_In_Current_City_Years Marital_Status Product_Category_1  \n",
       "357216                           2              0                  8  \n",
       "389881                           0              1                  8  \n",
       "34323                            1              0                  8  \n",
       "46172                            4              1                  8  \n",
       "379025                           3              0                  5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_var = ['Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years']\n",
    "#transformamos las variables categóricas en 0s y 1s\n",
    "for feature in level_var:\n",
    "    X.loc[:,feature] = LabelEncoder().fit_transform(X[feature])\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_0.0</th>\n",
       "      <th>Gender_1.0</th>\n",
       "      <th>Age_0.0</th>\n",
       "      <th>Age_1.0</th>\n",
       "      <th>Age_2.0</th>\n",
       "      <th>Age_3.0</th>\n",
       "      <th>Age_4.0</th>\n",
       "      <th>Age_5.0</th>\n",
       "      <th>Age_6.0</th>\n",
       "      <th>City_Category_0.0</th>\n",
       "      <th>City_Category_1.0</th>\n",
       "      <th>City_Category_2.0</th>\n",
       "      <th>Stay_In_Current_City_Years_0.0</th>\n",
       "      <th>Stay_In_Current_City_Years_1.0</th>\n",
       "      <th>Stay_In_Current_City_Years_2.0</th>\n",
       "      <th>Stay_In_Current_City_Years_3.0</th>\n",
       "      <th>Stay_In_Current_City_Years_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357216</th>\n",
       "      <td>1.754130</td>\n",
       "      <td>-1.754130</td>\n",
       "      <td>-0.168662</td>\n",
       "      <td>2.115054</td>\n",
       "      <td>-0.808863</td>\n",
       "      <td>-0.504309</td>\n",
       "      <td>-0.299071</td>\n",
       "      <td>-0.275152</td>\n",
       "      <td>-0.201183</td>\n",
       "      <td>-0.603814</td>\n",
       "      <td>1.170904</td>\n",
       "      <td>-0.671941</td>\n",
       "      <td>-0.395361</td>\n",
       "      <td>-0.737642</td>\n",
       "      <td>2.095293</td>\n",
       "      <td>-0.455805</td>\n",
       "      <td>-0.428126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389881</th>\n",
       "      <td>1.754130</td>\n",
       "      <td>-1.754130</td>\n",
       "      <td>-0.168662</td>\n",
       "      <td>-0.472801</td>\n",
       "      <td>1.236303</td>\n",
       "      <td>-0.504309</td>\n",
       "      <td>-0.299071</td>\n",
       "      <td>-0.275152</td>\n",
       "      <td>-0.201183</td>\n",
       "      <td>1.656139</td>\n",
       "      <td>-0.854041</td>\n",
       "      <td>-0.671941</td>\n",
       "      <td>2.529337</td>\n",
       "      <td>-0.737642</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>-0.455805</td>\n",
       "      <td>-0.428126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34323</th>\n",
       "      <td>1.754130</td>\n",
       "      <td>-1.754130</td>\n",
       "      <td>5.929021</td>\n",
       "      <td>-0.472801</td>\n",
       "      <td>-0.808863</td>\n",
       "      <td>-0.504309</td>\n",
       "      <td>-0.299071</td>\n",
       "      <td>-0.275152</td>\n",
       "      <td>-0.201183</td>\n",
       "      <td>1.656139</td>\n",
       "      <td>-0.854041</td>\n",
       "      <td>-0.671941</td>\n",
       "      <td>-0.395361</td>\n",
       "      <td>1.355672</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>-0.455805</td>\n",
       "      <td>-0.428126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46172</th>\n",
       "      <td>-0.570083</td>\n",
       "      <td>0.570083</td>\n",
       "      <td>-0.168662</td>\n",
       "      <td>-0.472801</td>\n",
       "      <td>-0.808863</td>\n",
       "      <td>-0.504309</td>\n",
       "      <td>-0.299071</td>\n",
       "      <td>-0.275152</td>\n",
       "      <td>4.970608</td>\n",
       "      <td>-0.603814</td>\n",
       "      <td>-0.854041</td>\n",
       "      <td>1.488225</td>\n",
       "      <td>-0.395361</td>\n",
       "      <td>-0.737642</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>-0.455805</td>\n",
       "      <td>2.335761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379025</th>\n",
       "      <td>-0.570083</td>\n",
       "      <td>0.570083</td>\n",
       "      <td>-0.168662</td>\n",
       "      <td>-0.472801</td>\n",
       "      <td>1.236303</td>\n",
       "      <td>-0.504309</td>\n",
       "      <td>-0.299071</td>\n",
       "      <td>-0.275152</td>\n",
       "      <td>-0.201183</td>\n",
       "      <td>-0.603814</td>\n",
       "      <td>-0.854041</td>\n",
       "      <td>1.488225</td>\n",
       "      <td>-0.395361</td>\n",
       "      <td>-0.737642</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.193918</td>\n",
       "      <td>-0.428126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender_0.0  Gender_1.0   Age_0.0   Age_1.0   Age_2.0   Age_3.0  \\\n",
       "357216    1.754130   -1.754130 -0.168662  2.115054 -0.808863 -0.504309   \n",
       "389881    1.754130   -1.754130 -0.168662 -0.472801  1.236303 -0.504309   \n",
       "34323     1.754130   -1.754130  5.929021 -0.472801 -0.808863 -0.504309   \n",
       "46172    -0.570083    0.570083 -0.168662 -0.472801 -0.808863 -0.504309   \n",
       "379025   -0.570083    0.570083 -0.168662 -0.472801  1.236303 -0.504309   \n",
       "\n",
       "         Age_4.0   Age_5.0   Age_6.0  City_Category_0.0  City_Category_1.0  \\\n",
       "357216 -0.299071 -0.275152 -0.201183          -0.603814           1.170904   \n",
       "389881 -0.299071 -0.275152 -0.201183           1.656139          -0.854041   \n",
       "34323  -0.299071 -0.275152 -0.201183           1.656139          -0.854041   \n",
       "46172  -0.299071 -0.275152  4.970608          -0.603814          -0.854041   \n",
       "379025 -0.299071 -0.275152 -0.201183          -0.603814          -0.854041   \n",
       "\n",
       "        City_Category_2.0  Stay_In_Current_City_Years_0.0  \\\n",
       "357216          -0.671941                       -0.395361   \n",
       "389881          -0.671941                        2.529337   \n",
       "34323           -0.671941                       -0.395361   \n",
       "46172            1.488225                       -0.395361   \n",
       "379025           1.488225                       -0.395361   \n",
       "\n",
       "        Stay_In_Current_City_Years_1.0  Stay_In_Current_City_Years_2.0  \\\n",
       "357216                       -0.737642                        2.095293   \n",
       "389881                       -0.737642                       -0.477260   \n",
       "34323                         1.355672                       -0.477260   \n",
       "46172                        -0.737642                       -0.477260   \n",
       "379025                       -0.737642                       -0.477260   \n",
       "\n",
       "        Stay_In_Current_City_Years_3.0  Stay_In_Current_City_Years_4.0  \n",
       "357216                       -0.455805                       -0.428126  \n",
       "389881                       -0.455805                       -0.428126  \n",
       "34323                        -0.455805                       -0.428126  \n",
       "46172                        -0.455805                        2.335761  \n",
       "379025                        2.193918                       -0.428126  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separamos las variables con más de 2 categorías\n",
    "\n",
    "X = pd.DataFrame(OneHotEncoder().fit(X[level_var]).transform(X[level_var]).toarray(), index=X.index, \n",
    "                               columns=OneHotEncoder().fit(X[level_var]).get_feature_names(level_var))\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns, index=X.index)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos el dataset en train y test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "#Aplicamos Random Forest como modelo de clasificación\n",
    "clf=RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
